{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# =============== tool ====================================\n",
    "\n",
    "prices = {\"London\": 150, \"Paris\": 70, \"Lisbon\": 120, \"Berlin\": 75}\n",
    "\n",
    "def ticket_price(city):\n",
    "    print(f\"the price of a ticket to {city} is {prices[city]}\")\n",
    "    return prices[city]\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ticket_price\",\n",
    "            \"description\": \"Get ticket prices to travel to a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# =========================== chatbot assistant =============================\n",
    "model_ = \"gpt4\"\n",
    "SYSTEM_PROMPT = \"You're an Assitant of a Airport Agency to help user to get some information\"\n",
    "\n",
    "\n",
    "def chat_func(msg, history):\n",
    "    history = [{\"role\": h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "\n",
    "    message = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + history + [{\"role\": \"user\", \"content\": msg}]\n",
    "\n",
    "    response = client.chat.completions.create(model = model_, messages=message, tools=tools)\n",
    "\n",
    "    return response.choices[0].message\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(fn = chat_func, type='messages')\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a65ca",
   "metadata": {},
   "source": [
    "### output of step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932662cb",
   "metadata": {},
   "source": [
    "#### Explaination\n",
    "\n",
    "1. LLM doesn't know the price >> should ask from \"ticket_price\" function\n",
    "2. LLM never sees the python function >> sees the function description (a list of a dictionary)\n",
    "3. user asks \"How much is a ticket to Paris?\"\n",
    "\n",
    "    in chat_func a message created:\n",
    "    message = [\n",
    "                {\"role\": \"system\", \"content\": \"You're an Assistant of an Airport Agency...\"},\n",
    "                {\"role\": \"user\", \"content\": \"How much is a ticket to Paris?\"}\n",
    "            ]\n",
    "\n",
    "4. LLM sees some info \"ticket\", \"price\", \"Paris\" >> call the tool\n",
    "\n",
    "    model output:\n",
    "        {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": null,\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "            \"id\": \"call_123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"ticket_price\",\n",
    "                \"arguments\": \"{\\\"city\\\": \\\"Paris\\\"}\"\n",
    "            }\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "\n",
    "    * content is null since model isn't answering yet\n",
    "\n",
    "5. Execute the tool >> python runs \"result = ticket_price(\"Paris\")\"\n",
    "\n",
    "    outputs: \n",
    "    the price of a ticket to Paris is 7070\n",
    "    70\n",
    "\n",
    "6. Python sends a message to the model (LLM)\n",
    "\n",
    "    {\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": \"call_123\",\n",
    "    \"name\": \"ticket_price\",\n",
    "    \"content\": \"70\"\n",
    "    }\n",
    "\n",
    "7. new message will be a combination of these roles: system, user, assistant, tool\n",
    "\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"How much is a ticket to Paris?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": null,\n",
    "            \"tool_calls\": [...]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": \"ticket_price\",\n",
    "            \"content\": \"70\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "8. final answer is:\n",
    "\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"A ticket to Paris costs 70 euros. Let me know if you'd like prices for other cities!\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# =============== tool ====================================\n",
    "\n",
    "prices = {\"London\": 150, \"Paris\": 70, \"Lisbon\": 120, \"Berlin\": 75}\n",
    "\n",
    "def ticket_price(city):\n",
    "    print(f\"the price of a ticket to {city} is {prices[city]}\")\n",
    "    return prices[city]\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ticket_price\",\n",
    "            \"description\": \"Get ticket prices to travel to a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# =========================== chatbot assistant =============================\n",
    "model_ = \"gpt4\"\n",
    "SYSTEM_PROMPT = \"You're an Assitant of a Airport Agency to help user to get some information\"\n",
    "\n",
    "\n",
    "def chat_func(msg, history):\n",
    "    history = [{\"role\": h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "\n",
    "    message = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + history + [{\"role\": \"user\", \"content\": msg}]\n",
    "\n",
    "    response = client.chat.completions.create(model = model_, messages=message, tools=tools)\n",
    "\n",
    "    assistant_msg = response.choices[0].message     # LLM isn't answering yet, should detect the tool calling\n",
    "\n",
    "    if assistant_msg.tool_calls:     # check tool calling, the result is None or a list of tool calls\n",
    "        tool_call = assistant_msg.tool_calls[0]\n",
    "\n",
    "        # get the arg from the LLM message and pass it to the python function\n",
    "        import json\n",
    "\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        city = args[\"city\"]\n",
    "\n",
    "        # call the function\n",
    "        tool_result = ticket_price(city)\n",
    "\n",
    "        # now we have the price, create the message \n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": tool_call.function.name,\n",
    "            \"content\": str(tool_result)\n",
    "        }\n",
    "\n",
    "        # And append messages\n",
    "        messages = message + [assistant_msg, tool_message]\n",
    "\n",
    "        # Second model call (final answer)\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=model_,\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        \n",
    "        return final_response.choices[0].message.content\n",
    "    \n",
    "    return assistant_msg.content\n",
    "\n",
    "demo = gr.ChatInterface(fn = chat_func, type='messages')\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
